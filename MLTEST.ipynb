{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20744e0-a986-4d21-a16f-9c4cba400e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageOps\n",
    "import tensorflow as tf\n",
    "from numpy import asarray\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "# from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6939cbf6-0d32-422e-a2f8-76bad6d8abf2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set the image and mask directory paths\n",
    "img_dir = 'Images'\n",
    "mask_dir = 'labels'\n",
    "\n",
    "# initialize empty lists to store the data\n",
    "images = []\n",
    "masks = []\n",
    "\n",
    "# loop over each image file and load the corresponding mask\n",
    "for filename in os.listdir(img_dir):\n",
    "    if filename.endswith('.png'):\n",
    "        # load the image and resize it\n",
    "        img = Image.open(os.path.join(img_dir, filename)).convert('RGB')\n",
    "        img = img.resize((256, 256))\n",
    "\n",
    "        # load the mask and resize it\n",
    "        mask = Image.open(os.path.join(mask_dir, filename))\n",
    "        mask = mask.resize((256, 256))\n",
    "\n",
    "        # normalize the image pixel values to be between 0 and 1\n",
    "        img = np.array(img) / 255.0\n",
    "        mask = np.array(mask) /255.0\n",
    "\n",
    "        # stack the image and mask together\n",
    "        # img_mask = np.dstack((img, mask))\n",
    "        # add the data to the corresponding lists\n",
    "        images.append(img)\n",
    "        masks.append(mask)\n",
    "\n",
    "# convert the data to numpy arrays\n",
    "images = np.array(images)\n",
    "masks = np.array(masks)\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(images, masks, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4abb7b2-8789-442e-a1d6-dce19008f981",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "lr=3e-4\n",
    "# sgd = SGD(lr=0.002, momentum=0.9)\n",
    "def multi_res_unet(input_shape):\n",
    "    # Input layer\n",
    "    inputs = Input(shape=input_shape)\n",
    "        # Encoder\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same')(conv4)\n",
    "    drop4 = Dropout(0.6)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    # Bottom\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    # Decoder\n",
    "    up6 = UpSampling2D(size=(2, 2))(drop5)\n",
    "    up6 = Conv2D(512, 2, activation='relu', padding='same')(up6)\n",
    "    merge6 = concatenate([drop4, up6], axis=3)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = UpSampling2D(size=(2, 2))(conv6)\n",
    "    up7 = Conv2D(256, 2, activation='relu', padding='same')(up7)\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = UpSampling2D(size=(2, 2))(conv7)\n",
    "    up8 = Conv2D(128, 2, activation='relu', padding='same')(up8)\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = UpSampling2D(size=(2, 2))(conv8)\n",
    "    up9 = Conv2D(64, 2, activation='relu', padding='same')(up9)\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
    "    conv9 = Conv2D(64, 3, activation='relu', padding='same')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation='relu', padding='same')(conv9)\n",
    "    out = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=out)\n",
    "    model.compile(optimizer=Adam(lr=lr), loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f97897e-0439-4f03-8094-6dcd21e20f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input image dimensions\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
    "img_width = 256\n",
    "img_height = 256\n",
    "img_channels = 3\n",
    "\n",
    "# Define input shape\n",
    "input_shape = (img_height, img_width, img_channels)\n",
    "\n",
    "# Define the U-Net architecture\n",
    "# inputs = Input(shape=input_shape)\n",
    "\n",
    "model = multi_res_unet(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420f6eb9-6097-49d3-906c-65b10095f3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the training set\n",
    "epochs = 120\n",
    "history = model.fit(X_train,Y_train, epochs=epochs, validation_data=(X_test,Y_test), batch_size=batch_size,callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb32c036-bc9c-4092-9b2c-fc58bb4ceea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_str = f\"Ploted_Data/e{epochs}_lr{lr}_bs{batch_size}.png\"\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Accuracy and Loss')\n",
    "plt.ylabel('Accuracy/Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Accuracy', 'Validation Accuracy', 'Loss', 'Validation Loss'], loc='upper left')\n",
    "plt.savefig(path_str)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773c8e81-05c4-46c8-bf67-ea389ac1f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = 'Testing'\n",
    "test = []\n",
    "\n",
    "# loop over each image file and load the corresponding mask\n",
    "for filename in os.listdir(img_dir):\n",
    "    if filename.endswith('.png'):\n",
    "        # load the image and resize it\n",
    "        img = Image.open(os.path.join(img_dir, filename)).convert('RGB')\n",
    "        img = img.resize((256, 256))\n",
    "        # normalize the image pixel values to be between 0 and 1\n",
    "        img = np.array(img)/255\n",
    "\n",
    "        test.append(img)\n",
    "\n",
    "# convert the data to numpy arrays\n",
    "test = np.array(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983781dc-a20b-4c33-87c3-31b1311e6f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test)\n",
    "y_pred[y_pred<np.mean(y_pred)]=0\n",
    "y_pred[y_pred>=np.mean(y_pred)]=1\n",
    "# Plot the original images and the corresponding segmentation masks\n",
    "for i in range(len(test)):\n",
    "    path_str = f\"Ploted_Data/result{i}.png\" \n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    axs[0].imshow(test[i], cmap='gray')\n",
    "    axs[1].imshow(y_pred[i,:,:,0], cmap='gray')\n",
    "    # plt.show()\n",
    "    plt.savefig(path_str)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1097f945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4842cd48-8c9c-4e7d-b4ff-71d8a41790a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
